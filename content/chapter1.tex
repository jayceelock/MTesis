\chapter{Introduction}
\label{chap1}

\section{Problem Statement}
\label{sec:problem-statement}

Remote controlled model aeroplanes have been in use for decades and have been a favourite among hobbyists for almost equally long. However, the past decade has arguably seen the greatest increase in computing power and efficiency since the silicon transistor was first invented (refer to the law popularised by~\citeauthor{moore2005cramming}, \citeyear{moore2005cramming}). Thanks to the growth in the mobile technology industries, computers have not only grown more powerful, but also smaller, lighter, cheaper and more power efficient. The increase in computing power and decrease in size and cost have made it possible to place small computers onto a model aeroplane with the aim of having it autonomously control, or semi-autonomously assist in controlling, a model aeroplane. 

Coupled with the rise in mobile computing power, control theory has also reached a point where it has a better understanding of the unstable, underactuated plant, such as a Segway, and manages to stabilise and control plants like these in some cases. One case of interest is a multirotor unmanned aerial vehicle (UAV) which resembles a model helicopter with multiple rotors. The so-called quadcopter configuration is of special interest for this research project.  

Autonomous UAVs are typically fitted with a multitude of sensors that provide the control system with the orientation and localisation data of the UAV.\@ These sensors normally include an accelerometer, gyroscope and GPS, along with others such as a barometer, optic flow sensor, magnetometer, etc. In its semi-autonomous state, the control system uses the sensor readings to keep the UAV level and stable while following a human pilot's flight instructions. Optionally, the pilot can engage the UAV in \emph{mission} mode where the UAV autonomously completes a flight mission selected by the pilot without the pilot controlling it. A mission consists of a set of GPS coordinate waypoints and altitudes for the UAV to follow. The pilot can also set the UAV to \emph{loitering} mode, where the UAV's control system will keep the UAV stable and level while holding the UAV's yaw angle and position constant. 

A consequence of the smaller and lighter sensors UAVs are typically equipp\-ed with is that they are often less accurate than their larger, more powerful counterparts. The implication this holds for UAVs in general can readily be observed from most UAVs in \emph{loiter} mode where there is often significant drift around the UAV's set point and the UAV would ideally not drift at all. The accuracy of the individual sensors are often known or can be determined, but due to the mathematical filtering and fusion of the different sensor readings, as well as other operations that the control system may perform on the sensor data, it is difficult to determine the resulting accuracy of the position and orientation measurements made by the UAV's sensor suite. As a result, the pose (a vector describing an object's position and orientation) estimation accuracy of an outdoor UAV is not yet known. This research project attempts to find and implement a reliable method to determine the pose estimation error of a typical quadcopter UAV.\@  

\section{Project Motivation}

For many years, UAVs have mostly been the playthings of hobbyists and the researchers studying them. In recent years, however, the improvements that have been made to UAVs, which include quad-, hexa- and octocopters, and their controllers have drawn the attention of large corporations, such as Amazon and DHL who are interested in incorporating UAVs into their respective workforces. 

Similarly, national governments have also noticed the increasing commercial and industrial potential that UAVs have, while also recognising the dangers that they pose to society if left unregulated. As such, many governments have moved to regulate and place restrictions on how and where UAVs may be used. The general trend of the regulations, as demonstrated by the regulations released by the~\cite{sacaa-drone-regs}, is that UAVs may be manually flown by a pilot anywhere below an altitude of $\SI{120}{\m}$, $\SI{50}{\m}$ away from people and buildings and $\SI{10}{\km}$ away from any aerodrome. These regulations allow for autonomous UAV flight, provided the UAV remain within radio line of sight of a human operator that can manually take over control of the UAV at any time should something go wrong. 

At the moment, UAVs are not as safe as they should be and can pose a serious health hazard to their surroundings and people if handled incorrectly. This, coupled with a general lack of hardware- and software-based collision avoidance capabilities, makes aviation authorities very cautious about allowing fully autonomous flight (i.e.\ out of radio line of sight). There are many safety improvements that can be made to UAVs, such as an improved control strategy, hardware improvements (such as rotor shrouds) and other fail-safe and collision avoidance systems. 

Having accurate pose data of a UAV in flight available is crucial to implementing an effective control strategy and collision avoidance system. As mentioned in Section~\ref{sec:problem-statement}, UAVs do not estimate their own pose very well and are prone to sensor drift over time. This allows for a `bubble' of pose uncertainty to be drawn around a UAV in flight, where the true pose of a UAV will be somewhere within the bubble, but the true pose is indeterminable. If the bubble's volume can be determined, it will allow a UAV's control system to generate safer, more efficient flight mission paths, which will improve the UAVs performance and make them a more attractive and safe option for governments and industry. 

\section{Existing and Proposed Solutions}

The current state-of-the-art method in determining the pose of a UAV in flight is to use an indoor motion tracking system, such as a Vicon\footnote{www.vicon.com/} system which uses a set of infrared cameras to track markers placed on an object. However, such systems cannot be used in this case since the UAVs of interest to this project require access to their GPS coordinates. The GPSs used in this project require a strong connection to at least 6 different GPS satellites to produce accurate position data. These GPSs are also low-powered and small and therefore struggle to make good connections to satellites when indoors. It was therefore decided that the quadcopters would be flown in the outdoors for this project. This implies that an outdoor pose measurement system is required. 

Outdoor pose measurement systems, such as radar- or laser-based systems, can also be used to perform pose measurements of a UAV.\@ However, these systems normally come at a premium cost and were unavailable at the time this project was undertaken. It was therefore decided to investigate and implement another pose measurement method that is cheap, accurate, repeatable and easy to use. 

The proposed outdoor UAV pose measurement system is based on computer vision techniques where the pose data of an object can be extracted from image or video data containing the object. The system consists of a camera to capture the image data and a computer to perform the pose data extraction. 

\section{Project Objectives}

The objectives of this research project are as follows. 

\begin{itemize}
  \item Design and implement a computer vision pose measurement system.
  \item Determine the measurement accuracy of the computer vision system.
  \item Use the computer vision system to determine the pose estimation accuracy of a demonstration quadcopter in flight. 
\end{itemize}

\section{Report Structure}

This document begins with a review of existing literature and of previous research results in the fields relevant to this project, such as computer vision techniques, UAV control strategies and others. Afterwards, the design and implementation, as well as the determination of the accuracy of the computer vision pose estimation system is discussed. This is followed by a discussion on how the pose measurement error of the computer vision system was determined for subsequent measurements and used to determine the pose estimation accuracy of a quadcopter in flight. Finally, a conclusion on the significant findings and results, as well as shortcomings and potential improvements, are presented. 
